---
layout:     post                    # 使用的布局
title:      Machine Learning               # 标题 
subtitle:   #副标题
date:       2019-01-04              # 时间
author:     Doublefierce                      # 作者
header-img: img/bg-post.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - ML
---

### 正则化

> **L0、L1、L2范数**
>  监督机器学习问题无非就是“minimizeyour error while regularizing your parameters”，也就是在规则化参数的同时最小化误差。最小化误差是为了让我们的模型拟合我们的训练数据，而规则化参数是防止我们的模型过分拟合我们的训练数据。多么简约的哲学啊！因为参数太多，会导致我们的模型复杂度上升，容易过拟合，也就是我们的训练误差会很小。但训练误差小并不是我们的最终目标，我们的目标是希望模型的测试误差小，也就是能准确的预测新的样本。所以，我们需要保证模型“简单”的基础上最小化训练误差，这样得到的参数才具有好的泛化性能（也就是测试误差也小），而模型“简单”就是通过规则函数来实现的。另外，规则项的使用还可以约束我们的模型的特性。这样就可以将人对这个模型的先验知识融入到模型的学习当中，强行地让学习到的模型具有人想要的特性，例如稀疏、低秩、平滑等等。要知道，有时候人的先验是非常重要的。前人的经验会让你少走很多弯路，这就是为什么我们平时学习最好找个大牛带带的原因。一句点拨可以为我们拨开眼前乌云，还我们一片晴空万里，醍醐灌顶。对机器学习也是一样，如果被我们人稍微点拨一下，它肯定能更快的学习相应的任务。只是由于人和机器的交流目前还没有那么直接的方法，目前这个媒介只能由规则项来担当了。
> http://blog.csdn.net/zouxy09/article/details/24971995
> **核范数与规则项参数选择**
> https://blog.csdn.net/zouxy09/article/details/24972869
> **什么是正则化**
> https://charlesliuyx.github.io/2017/10/03/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E4%BB%80%E4%B9%88%E6%98%AF%E6%AD%A3%E5%88%99%E5%8C%96/

### 数据标准化/归一化
>数据的标准化是将数据按比例缩放，使之落入一个小的特定空间。在某些比较和评价的指标处理中经常会用到，去除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行比较和加权。
>目前数据标准化方法有很多，归结起来可以分为直线型方法(如极值法、标准差法)、折线型法（如三折线型法）、曲线型法（如半正态性分布）。不同的标准化方法，对系统的评价结果会产生不同的影响，然而不幸的是，在数据标准化方法的选择上，还没有通用的法则可以遵循。其中最典型的就是数据的归一化处理，即将数据统一映射到 [0，1] 区间上。
>https://blog.csdn.net/pipisorry/article/details/52247379
>**什么是批标准化 (Batch Normalization)**
>https://zhuanlan.zhihu.com/p/24810318
>**深入理解Batch Normalization批标准化**
>https://www.cnblogs.com/guoyaohua/p/8724433.html
>**关于Batch Normalization的另一种理解**
>https://blog.csdn.net/AIchipmunk/article/details/54234646

### 过拟合
>https://mp.weixin.qq.com/s/-kKGlqmpCiW_lyZShusazw
>https://www.zhihu.com/question/59201590/answer/167392763


### 生成模型与判别模型
> 生成方法由数据学习联合概率分布P(X,Y),然后求出条件概率分布P(Y|X)作为预测 的模型，典型的生成模型有：朴素贝叶斯法和隐马尔科夫模型。判别方法由数据直接学习决策函数f(X)或者条件概率分布P(Y|X)作为预测的模型，典型的判别模型包括：k近邻、感知机、决策树、逻辑斯蒂回归模型、最大熵模型、支持向量机、提升方法和条件随机场。
> https://blog.csdn.net/zouxy09/article/details/8195017




### 验证集与测试集的区别
> https://blog.csdn.net/jmh1996/article/details/79838917

### 频率学派还是贝叶斯学派
>https://blog.csdn.net/yH0VLDe8VG8ep9VGe/article/details/78999639

### 先验概率还是后验概率
>https://blog.csdn.net/fjssharpsword/article/details/72356277